{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3388d-66b9-414b-b2d5-25d1bb45f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1: \"Web scraping\"\n",
    "It is the process of extracting data from websites using automated softwares or tools.\n",
    "the software or tools are progrsmmed to parse the HTML or others sources code of web pages , \n",
    "identify specific elements of interest, and extract the relevant data.\n",
    " web scraping is used for a  variety of purposes, such as :\n",
    "1.Business Intelligence\n",
    "2.Data Collection\n",
    "3.Research\n",
    "\n",
    "Some other areas where web scraping is used include:\n",
    "\n",
    ".E-commerce\n",
    ".Job market Analysis\n",
    ".Real Estste\n",
    "\n",
    "Overall, web scraping is a powerful tool for gathering data from websites and can be\n",
    "used in a wide variety of industries and applications. \n",
    "  However, it is important to use web scraping ethically and legally, respecting \n",
    "    website owners  terms of service and any relevant laws and regulations.\n",
    "\n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab589c4-848f-4eaa-948e-b66dbe0a32ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28b05b-c24f-41d6-80df-9dc551974c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2:There are several methods used for web scraping, here are some methods \n",
    "\n",
    "\"Example\":\n",
    "1.Manual Scraping\n",
    "2.DOM Parsing\n",
    "3.Web Scraping Tools\n",
    "4.API Scraping\n",
    "5.Browser Extension Scraping\n",
    "6.RSS Scraping\n",
    "7.Optical Character Recognition (OCR) Scraping\n",
    "8.Human-in-the-Loop Scraping\n",
    "9.Deep Web Scraping\n",
    "10.Machine Learning Scraping:\n",
    "\n",
    "Overall, the method used for web scraping will depend on the specific needs of the\n",
    "project, the amount of data to be scraped, and the technical expertise of the scraper.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979f1e8-ff4f-42df-8b89-cc39164ecc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d2656-90f2-4bb9-af20-6b7ea5aed079",
   "metadata": {},
   "outputs": [],
   "source": [
    "3:Beautiful Soup is a Python library that is used for web scraping purposes to extract\n",
    "data from HTML and XML files. It is a popular tool for web scraping due to its ease\n",
    "of use, flexibility, and powerful features.\n",
    " \n",
    "Beautiful Soup provides a simple and intuitive interface for parsing HTML and XML files\n",
    "and extracting data from specific elements such as tags, attributes, and text. It can\n",
    "be used to navigate and search the HTML structure of a web page, and to extract data\n",
    "from specific parts of the page.\n",
    "\n",
    "\"Some of the key features of Beautiful Soup\"\n",
    ".Easy to Install and Use\n",
    ".Robust HTML Parsing\n",
    ".Powerful Data Extraction\n",
    ".Integration with Other Libraries\n",
    "\n",
    "\n",
    "Overall, Beautiful Soup is a versatile and powerful tool for web scraping in Python,\n",
    "and is widely used by data scientists, researchers, and web developers...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db90e6d-2688-4b11-a05d-9ac40c3c6614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efeb36e-9202-458d-90ee-d9a5e8fb43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "4:Flask is used in this web scraping project to build a web scraper app.\n",
    "Flask is a popular Python web development framework that is easy to use and allows\n",
    "developers to create backend code quickly. Flask is often used for building\n",
    "smaller websites, while Django is used for larger projects.\n",
    "\n",
    "\"Flask is a good choice for web scraping projects for several reasons\"\n",
    "\n",
    ".Server-side Processing\n",
    ".Easy to Use\n",
    ".Integration with Other Libraries \n",
    ".Flexibility\n",
    "\n",
    "Flask allows developers to quickly build custom web scraping applications that can \n",
    "handle large amounts of data and traffic.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a85bce-5310-45b5-990b-8bcbd19eb2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2196447-0c0c-4782-9f46-8c6df16b8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "5:AWS provides a wide range of services that can be used to build and deploy web \n",
    "scrapers, including compute, storage, database, and monitoring services. \n",
    "  By leveraging these services, developers can build scalable, reliable, and cost-effective \n",
    "web scrapers that can handle large amounts of data and traffic.\n",
    "\n",
    "'Here are some AWS services that can be used in a web scraping project':\n",
    "1.Amazon EC2: Provides scalable virtual servers in the cloud.\n",
    "2.AWS Lambda: Runs code in the cloud without provisioning or managing servers.\n",
    "3.Amazon S3: Provides highly scalable and durable storage for objects, such as \n",
    "             HTML pages or images.\n",
    "4.Amazon CloudWatch: Provides monitoring and management of AWS resources,\n",
    "                     applications, and services for web scraping jobs.\n",
    "5.Amazon DynamoDB: Provides fast and scalable NoSQL database storage for\n",
    "                   structured data.\n",
    "6.Amazon API Gateway: Allows developers to create, publish, and manage APIs to\n",
    "                      access web scraping data in a structured format.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee534904-e260-4cd5-8bf5-a8f98307ce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
